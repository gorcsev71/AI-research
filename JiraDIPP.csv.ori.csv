Summary,Issue key,Issue id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project lead id,Project description,Priority,Resolution,Assignee,Assignee Id,Reporter,Reporter Id,Creator,Creator Id,Created,Updated,Last Viewed,Resolved,Due date,Votes,Labels,Labels,Labels,Description,Environment,Watchers,Watchers,Watchers,Watchers,Watchers Id,Watchers Id,Watchers Id,Watchers Id,Original estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Inward issue link (Blocks),Outward issue link (Blocks),Outward issue link (Blocks),Inward issue link (Cloners),Inward issue link (Cloners),Outward issue link (Cloners),Inward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Outward issue link (Relates),Attachment,Attachment,Attachment,Custom field (Development),Custom field (Issue color),Custom field (Rank),Sprint,Sprint,Sprint,Custom field (Start date),Custom field (Story point estimate),Comment,Comment,Comment,Comment,Parent,Parent summary,Status Category
Save trips as JSON regardless of the schema,DIPP-64,10063,Story,To Do,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,,,Adam_Aranyi,63cfe31ba05386069cda49af,Adam_Aranyi,63cfe31ba05386069cda49af,27/Mar/23 9:40 AM,27/Mar/23 9:42 AM,30/Mar/23 12:58 PM,,,0,TechDebt,,,"The schema provided for the futar API is not reliable. The data provided by the API frequently contains fields that are not present in the schema. 

Instead of constantly maintaining the schema I want to store all the retrieved data as is in JSON format.",,Adam_Aranyi,,,,63cfe31ba05386069cda49af,,,,,,,,,,,,,DIPP-60,,,,,,,,,,,,,,,0|i00067:,,,,,,,,,,,,To Do
CI/CD pipeline (Python),DIPP-63,10062,Story,Review,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Adam Brett,63d39e92f6e1b543161772c7,Gábor Fábián,63cfe31ba197e05f9dad5aa6,22/Mar/23 10:42 AM,30/Mar/23 9:11 AM,30/Mar/23 12:59 PM,,,0,,,,"Create a CI/CD pipeline.

Check if creating an artifactory is possible.

If the pipeline fails then send an email

*Hint:* [https://gitbud.epam.com/andor_herendi/bkk/-/pipelines|https://gitbud.epam.com/andor_herendi/bkk/-/pipelines]

AC

* -The repository can be built-
* Tests are executed
* Code formatter executed
* If any of the previous steps failing then the whole pipeline is failing
* The pipeline is triggered after each and every commit",,Gábor Fábián,,,,63cfe31ba197e05f9dad5aa6,,,,,,,,,,,,,,,,,DIPP-52,,,,,,,,,,,0|i0005z:,,,,,5.0,,,,,,,In Progress
Visualize delays in PowerBI,DIPP-62,10061,Story,In Progress,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,Levente_Nagy1,63cfe31bf386bda5dcab317d,Andor Herendi,63ce6514f6e1b5431616179f,Andor Herendi,63ce6514f6e1b5431616179f,06/Mar/23 9:22 AM,29/Mar/23 9:05 AM,30/Mar/23 12:59 PM,,,0,DelaysPerLineVisualization,,,Create a visualization which displays the delays per line in PowerBI,,Andor Herendi,,,,63ce6514f6e1b5431616179f,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0005q:i,DIPP Sprint 6,,,,8.0,,,,,,,In Progress
Introduce a working Loki instance,DIPP-61,10060,Story,To Do,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Andor Herendi,63ce6514f6e1b5431616179f,Andor Herendi,63ce6514f6e1b5431616179f,06/Mar/23 9:20 AM,23/Mar/23 9:19 AM,30/Mar/23 12:59 PM,,,0,Logging,,,Create a working Loki instance which is containerized and accessible through Web browser.,,Andor Herendi,,,,63ce6514f6e1b5431616179f,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0005r:,,,,,,,,,,,,To Do
Certain trip entries cause unhandled error at trip ingestion,DIPP-60,10059,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam_Aranyi,63cfe31ba05386069cda49af,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Gábor Fábián,63cfe31ba197e05f9dad5aa6,03/Mar/23 12:45 PM,30/Mar/23 9:02 AM,30/Mar/23 12:59 PM,30/Mar/23 9:02 AM,,0,Ingestion,TechDebt,,"Certain trip entries cause unhandled error (likely because they contain different fields).

See:

[https://dataint23.atlassian.net/browse/DIPP-19|https://dataint23.atlassian.net/browse/DIPP-19|smart-link]

[https://dataint23.atlassian.net/browse/DIPP-43|https://dataint23.atlassian.net/browse/DIPP-43|smart-link]",,Adam_Aranyi,Gábor Fábián,,,63cfe31ba05386069cda49af,63cfe31ba197e05f9dad5aa6,,,,,,,,,,,DIPP-64,,,,,,,,,,,07/Mar/23 9:16 AM;63cfe31ba05386069cda49af;stacktrace.txt;https://dataint23.atlassian.net/secure/attachment/10000/stacktrace.txt,07/Mar/23 11:23 AM;63cfe31ba05386069cda49af;stacktrace_avroTypeException.txt;https://dataint23.atlassian.net/secure/attachment/10001/stacktrace_avroTypeException.txt,08/Mar/23 6:30 PM;63cfe31ba05386069cda49af;trip_containing_unfamiliar_fields.txt;https://dataint23.atlassian.net/secure/attachment/10003/trip_containing_unfamiliar_fields.txt,,,0|i0000f:ie,DIPP Sprint 4,DIPP Sprint 5,DIPP Sprint 6,,1.0,"07/Mar/23 1:33 PM;63cfe31ba05386069cda49af;Found the cause of the AvroTypeException. Some trips contain an additional attribute called ""nextBlockTripId"" which is not in the schema therefore cannot be parsed.",08/Mar/23 6:36 PM;63cfe31ba05386069cda49af;The futar api sometimes returns values which are not present in the original schema. For example one of the trips has a field called 'secondaryColor' (trip_containing_unfamiliar_fields.txt line 34) which is not present in[ futar-openapi.yaml|https://editor.swagger.io/?url=https://opendata.bkk.hu/docs/futar-openapi.yaml].,,,,,Done
Rewrite Futár API to read avro files,DIPP-59,10058,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Botond_Besnyi,63cfe31bc7e5fd35203b3219,03/Mar/23 9:22 AM,22/Mar/23 12:10 PM,30/Mar/23 12:59 PM,22/Mar/23 12:10 PM,,0,2_approve,2_review,Ingestion,Rewrite Futár API to read avro files instead of txt,,Botond_Besnyi,,,,63cfe31bc7e5fd35203b3219,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0000f:ii,DIPP Sprint 4,DIPP Sprint 5,DIPP Sprint 6,,2.0,03/Mar/23 5:15 PM;63cfe31bc7e5fd35203b3219;[PR|https://git.epam.com/adam_posta/bkk/-/merge_requests/4],,,,,,Done
Rewrite timetable ingestion to fastavro,DIPP-58,10057,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Botond_Besnyi,63cfe31bc7e5fd35203b3219,02/Mar/23 9:23 AM,28/Mar/23 11:09 PM,30/Mar/23 12:59 PM,28/Mar/23 11:09 PM,,0,1_review,3_approve,Ingestion,Change the timetable ingestion’s code to use fastavro instead of pandavro,,Botond_Besnyi,,,,63cfe31bc7e5fd35203b3219,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0000f:if,DIPP Sprint 4,DIPP Sprint 5,DIPP Sprint 6,,2.0,02/Mar/23 9:39 AM;63cfe31bc7e5fd35203b3219;[PR|https://git.epam.com/botond_besnyi/suhu/-/merge_requests/3],,,,,,Done
Handling the case when required env vars are missing or empty,DIPP-57,10056,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Feb/23 9:11 AM,27/Mar/23 11:04 AM,30/Mar/23 12:59 PM,27/Mar/23 11:04 AM,,0,1_approve,1_review,TechDebt,"If the input data type is not defined then the error message is misleading



AC

* The error message is descriptive and understandable
* Unit test completed
* Merged into main branch



According to Andor Herendi, a simple null check does its job.



The app accepts {{TripUpdates}} or {{VehiclePositions}} as input data type. {{trip_ingestion}} is not accepted.

{code:java}PS C:\Users\Andor_Herendi\projects\bkk\gabor_fabian> docker run -e BKK_BASE_URL=https://go.bkk.hu/api/query/v1/ws/gtfs-rt/full/ trip_ingestion
Exception in thread ""main"" java.lang.NullPointerException: Cannot invoke ""String.hashCode()"" because ""<local3>"" is null
        at com.epam.suhudata01.bkk.App.getFeedMessageDataFetcher(App.java:46)
        at com.epam.suhudata01.bkk.App.main(App.java:32)
{code}",,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0000f:ik,DIPP Sprint 6,,,,1.0,,,,,,,Done
Tech Debt,DIPP-56,10055,Epic,To Do,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,,,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,24/Feb/23 9:21 AM,24/Feb/23 9:21 AM,30/Mar/23 12:59 PM,,,0,,,,,,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,,,,,,,,,,purple,0|i0004n:,,,,,,,,,,,,To Do
TechDebt - Modularize Python projects,DIPP-55,10054,Story,To Do,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,,,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,21/Feb/23 1:02 PM,24/Feb/23 9:21 AM,30/Mar/23 12:59 PM,,,0,TechDebt,,,"As a developer, I want to modularize all Python project so that we can have a unified and more maintainable codebase.

*AC:*

* Separate the functionality of a program into independent, interchangeable modules.",,Adam Brett,,,,63d39e92f6e1b543161772c7,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0004f:,,,,,,,,,,10055,Tech Debt,To Do
TechDebt - Measure code coverage in Python,DIPP-54,10053,Story,To Do,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,,,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,21/Feb/23 12:52 PM,24/Feb/23 9:21 AM,30/Mar/23 12:59 PM,,,0,TechDebt,,,"As a developer, I want to measure the code coverage of individual modules, so that I can be more certain relevant code paths are complying the expected behaviour.

*Acceptance Criteria (AC):*

* Try coverage.py to measure code coverage
* Report to be created about code coverage (should not be stored anywhere)
* Minimum coverage is not lower than 60%
* If the target is not met then the build should fail",,Adam Brett,,,,63d39e92f6e1b543161772c7,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i00047:,,,,,,,,,,10055,Tech Debt,To Do
Data transformation of TripUpdates source to dim_stop table,DIPP-53,10052,Story,Review,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,Adam_Posta,63cfe31bc565900ff4050272,Adam Brett,63d39e92f6e1b543161772c7,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,14/Feb/23 10:48 AM,21/Mar/23 5:56 PM,30/Mar/23 12:59 PM,,,0,1_review,2_approve,,"As a developer I want to create a transformation
that processes the TripUpdates source according to the DFD (Data Flow Diagram)
and writes the output to *_dim_stop_* table.

*AC:*

* use Python
* write output to SQLite
* Store dates with timezone information 
* persist only once after the vehicle reached the last stop

DFD diagram: [https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|smart-link]",,Adam_Posta,Tamas Adami,,,63cfe31bc565900ff4050272,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,DIPP-45,,,,,,,,,,,0|i0000g:,DIPP Sprint 4,DIPP Sprint 5,DIPP Sprint 6,,5.0,"21/Mar/23 5:56 PM;63cfe31bc565900ff4050272;All threads are resolved, waiting for final approval",,,,10015,Data Transformation,In Progress
CI/CD pipeline (Java),DIPP-52,10051,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,09/Feb/23 12:23 PM,29/Mar/23 10:27 AM,30/Mar/23 12:59 PM,29/Mar/23 10:27 AM,,0,2_approve,2_review,,"Investigate the possibilities of creating a CI/CD pipeline.

Check if creating an artifactory is possible.

If the pipeline fails then send an email

*Hint:* [https://gitbud.epam.com/andor_herendi/bkk/-/pipelines|https://gitbud.epam.com/andor_herendi/bkk/-/pipelines]

AC

* The repository can be built
* Tests are executed
* Code formatter executed
* If any of the previous steps failing then the whole pipeline is failing
* The pipeline is triggered after each and every commit",,Adam Brett,,,,63d39e92f6e1b543161772c7,,,,,,,,,,,,,,,DIPP-63,,,,,,,,,,,,,0|i0000f:is,DIPP Sprint 5,DIPP Sprint 6,,,5.0,,,,,10050,Design and create CI/CD pipeline ,Done
Design and create CI/CD pipeline ,DIPP-51,10050,Epic,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,,,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,09/Feb/23 12:17 PM,29/Mar/23 10:27 AM,30/Mar/23 12:59 PM,29/Mar/23 10:27 AM,10/Apr/23 12:00 AM,0,,,,"As a developer I want to create a CI/CD pipeline
so that builds, tests and deployments can be automated and new versions of software can be delivered easily.",,Adam Brett,,,,63d39e92f6e1b543161772c7,,,,,,,,,,,,,,,,,,,,,,,,,,,purple,0|i0003r:,,,,14/Mar/23 12:00 AM,,,,,,,,Done
Add logging for python modules,DIPP-50,10049,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,,,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,09/Feb/23 12:00 PM,06/Mar/23 9:46 AM,30/Mar/23 12:59 PM,06/Mar/23 9:46 AM,,0,,,,"As a developer I want to configure logging for all Python modules
so that the application can be properly monitored.

*AC:*

* logging is wired in into all Python related modules

Notes:

* [https://docs.python.org/3/library/logging.html|https://docs.python.org/3/library/logging.html|smart-link] ",,Adam Brett,Tamas Adami,,,63d39e92f6e1b543161772c7,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0003j:,,,,,,06/Mar/23 9:46 AM;557058:75793878-96f9-421a-b729-5480491e22d6;Already done as discussed,,,,,,Done
Code coverage are measured in Java module (Alerts),DIPP-49,10048,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam_Aranyi,63cfe31ba05386069cda49af,Andor Herendi,63ce6514f6e1b5431616179f,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,06/Feb/23 10:13 AM,14/Feb/23 5:57 PM,30/Mar/23 12:59 PM,14/Feb/23 5:57 PM,,0,BKK,,,"As a developer, I want to measure the code coverage of individual modules, so that I can be more certain relevant code paths are complying the expected behavior.



Acceptance Criteria (AC)

* Jacoco must be used to measure code coverage
* Report to be created about code coverage (should not be stored anywhere)
* Minimum coverage is not lower than 60%
* If the target is not met then the build should fail",,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,DIPP-29,,,,,,,,,,,0|i00033:i,DIPP Sprint 3,,,,5.0,,,,,,,Done
Create fact_delay table ,DIPP-48,10047,Story,In Progress,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,Adam_Aranyi,63cfe31ba05386069cda49af,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,06/Feb/23 10:04 AM,23/Mar/23 11:50 AM,30/Mar/23 12:59 PM,,,0,,,,"As a developer I want to create a transformation
that calculates the *delay* from the *_dim_stop_* and *_dim_stop_times_* tables' *_arrival_time_* column
and writes the output to *_fact_delay_* table according to the star schema.

*AC:*

* use Python
* read from the dim_stop and dim_stop_times tables
* write output to SQLite
* Store dates with timezone information

 

DFD diagram: [https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|smart-link]",,Adam Brett,,,,63d39e92f6e1b543161772c7,,,,,,,,,,,,,,,,,DIPP-47,,,,,,,,,,,0|i0005q:9,DIPP Sprint 6,,,,8.0,,,,,10015,Data Transformation,In Progress
Data transformation of TripUpdates source to dim_vehicle table,DIPP-47,10046,Story,Review,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,Kerecsen Szabo,63f4acc63ec8aa51d3d1ea7f,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,06/Feb/23 9:38 AM,23/Mar/23 9:34 AM,30/Mar/23 12:59 PM,,,0,1_review,2_approve,,"As a developer I want to create a transformation
that processes the TripUpdates source according to the DFD (Data Flow Diagram)
and writes the output to *_dim_vehicle_* table.

*AC:*

* use Python
* read avro files from blob storage (local disk)
* write output to SQLite
* Store dates with timezone information
* Sql script for table creation stored seperately and can be executed by hand

 

DFD diagram: [https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|smart-link]",,Adam Brett,Kerecsen Szabo,,,63d39e92f6e1b543161772c7,63f4acc63ec8aa51d3d1ea7f,,,,,,,,,,,,,,DIPP-48,,DIPP-46,,,,,,,,,,,0|i0000f:i9,DIPP Sprint 4,DIPP Sprint 5,DIPP Sprint 6,,5.0,20/Mar/23 11:56 AM;63f4acc63ec8aa51d3d1ea7f;[MR|https://git.epam.com/adam_posta/bkk_transform_data/-/merge_requests/3],,,,10015,Data Transformation,In Progress
Data transformation of TripUpdates source to dim_trip table,DIPP-46,10045,Story,Review,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,06/Feb/23 9:34 AM,21/Mar/23 9:03 AM,30/Mar/23 12:59 PM,,,0,1_approve,,,"As a developer I want to create a transformation
that processes the TripUpdates source according to the DFD (Data Flow Diagram)
and writes the output to *_dim_trip_* table.

*AC:*

* use Python
* read avro files from blob storage (local disk)
* write output to SQLite
* Store dates with timezone information
* Sql script for table creation stored seperately and can be executed by hand

 

DFD diagram: [https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|smart-link]",,Adam Brett,Botond_Besnyi,,,63d39e92f6e1b543161772c7,63cfe31bc7e5fd35203b3219,,,,,,,,,,,,,,DIPP-47,,DIPP-45,,,,,,,,,,,0|i0000f:m,DIPP Sprint 4,DIPP Sprint 5,DIPP Sprint 6,,5.0,28/Feb/23 9:22 AM;63cfe31bc7e5fd35203b3219;[Merge request|https://git.epam.com/botond_besnyi/bkk-data-transformation/-/merge_requests/1],,,,10015,Data Transformation,In Progress
Data transformation of TripUpdates source to dim_stop table,DIPP-45,10044,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam_Posta,63cfe31bc565900ff4050272,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,06/Feb/23 9:28 AM,20/Feb/23 12:48 PM,30/Mar/23 12:59 PM,20/Feb/23 12:48 PM,,0,1_review,,,"As a developer I want to create a transformation
that processes the TripUpdates source according to the DFD (Data Flow Diagram)
and writes the output to *_dim_stop_* table.

*AC:*

* use Python
* read avro files from blob storage (local disk)
* Store dates with timezone information 
* persist only once after the vehicle reached the last stop





DFD diagram: [https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|smart-link]",,Adam_Posta,Adam Brett,,,63cfe31bc565900ff4050272,63d39e92f6e1b543161772c7,,,,,,,,,,,,,,DIPP-46,DIPP-53,DIPP-44,,,,,,,,,,,0|i00039:18r,DIPP Sprint 3,,,,2.0,16/Feb/23 4:25 PM;63cfe31bc565900ff4050272;[https://git.epam.com/adam_posta/bkk_transform_data/-/merge_requests/1|https://git.epam.com/adam_posta/bkk_transform_data/-/merge_requests/1],,,,10015,Data Transformation,Done
Data transformation of static schedule to dim_stop_times table,DIPP-44,10043,Story,Review,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,Levente_Nagy1,63cfe31bf386bda5dcab317d,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,06/Feb/23 9:16 AM,28/Mar/23 3:04 AM,30/Mar/23 12:59 PM,,,0,0_approve,1_review,,"As a developer I want to create a transformation
that processes the static time schedule (*_stop_times.txt_*) according to the DFD (Data Flow Diagram)
and writes the output to *_dim_stop_times_* table.

*AC:*

* use Python
* read avro files from blob storage (local disk)
* write output to SQLite
* Store dates with timezone information
* Sql script for table creation stored seperately and can be executed by hand


DFD diagram: [https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|smart-link] ",,Adam Brett,,,,63d39e92f6e1b543161772c7,,,,,,,,,,,,,,,DIPP-45,,,,,,,,,,,,,0|i0000f:j,DIPP Sprint 4,DIPP Sprint 5,DIPP Sprint 6,,5.0,,,,,10015,Data Transformation,In Progress
Futár API Ingestion is containerized,DIPP-43,10042,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam_Aranyi,63cfe31ba05386069cda49af,Andor Herendi,63ce6514f6e1b5431616179f,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,03/Feb/23 10:37 AM,28/Mar/23 2:12 PM,30/Mar/23 12:59 PM,28/Mar/23 9:12 AM,,0,2_approve,,,"As a developer, I want to containerize the Futár API ingestion, so that can run as a platform-independent service.

AC

* Ingestion can be executed and can be configured through Docker
* The same Python version must be used through the build as the application written",,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,DIPP-42,,,,,,,,,,,0|i0000f:id,DIPP Sprint 4,DIPP Sprint 5,DIPP Sprint 6,,3.0,,,,,10021,Docker Compose,Done
Weather Ingestion is containerized,DIPP-42,10041,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam_Aranyi,63cfe31ba05386069cda49af,Andor Herendi,63ce6514f6e1b5431616179f,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,03/Feb/23 10:36 AM,28/Mar/23 5:07 PM,30/Mar/23 12:59 PM,28/Mar/23 5:07 PM,,0,2_approve,,,"As a developer, I want to containerize the weather ingestion, so that can run as a platform-independent service.

AC

* Ingestion can be executed and can be configured through Docker
* The same Python version must be used through the build as the application written",,Adam_Aranyi,Tamas Adami,,,63cfe31ba05386069cda49af,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,DIPP-43,,DIPP-32,,,,,,,,,,,0|i0000f:il,DIPP Sprint 4,DIPP Sprint 5,DIPP Sprint 6,,3.0,23/Mar/23 11:53 AM;63cfe31ba05386069cda49af;Currently everything is in the root folder. It would be better if code could be executed as a module. This will also require adjustments to the containerization.,,,,10021,Docker Compose,Done
Alert Ingestion is containerized,DIPP-41,10040,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Adam_Aranyi,63cfe31ba05386069cda49af,Adam_Aranyi,63cfe31ba05386069cda49af,03/Feb/23 10:34 AM,08/Mar/23 4:46 PM,30/Mar/23 12:59 PM,08/Mar/23 4:46 PM,,0,2_approve,,,"As a developer, I want to containerize the alert ingestion, so that can run as a platform-independent service.

 

AC

* Ingestion can be executed and can be configured through Docker
* The same Java version must be used through the build as the application written",,Adam_Aranyi,,,,63cfe31ba05386069cda49af,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0000i:zr,DIPP Sprint 4,DIPP Sprint 5,,,2.0,,,,,10021,Docker Compose,Done
Timetable Ingestion is containerized,DIPP-40,10039,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Andor Herendi,63ce6514f6e1b5431616179f,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,03/Feb/23 10:13 AM,08/Mar/23 4:06 PM,30/Mar/23 12:59 PM,08/Mar/23 4:06 PM,,0,3_approve,,,"As a developer, I want to containerize the timetable ingestion, so that can run as a platform-independent service.

AC

* Ingestion can be executed and can be configured through Docker
* The same Python version must be used through the build as the application written",,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,DIPP-32,,,,,,,,,,,0|i0000i:zv,DIPP Sprint 4,DIPP Sprint 5,,,3.0,,,,,10021,Docker Compose,Done
Timeout is introduced for the Alert Ingestion when BKK Service replies slowly,DIPP-39,10038,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam_Aranyi,63cfe31ba05386069cda49af,Adam_Aranyi,63cfe31ba05386069cda49af,Adam_Aranyi,63cfe31ba05386069cda49af,03/Feb/23 9:53 AM,21/Feb/23 11:28 AM,30/Mar/23 12:59 PM,21/Feb/23 11:28 AM,,0,,,,"As a developer, I want to stop the alert ingestion service when the alert data endpoint replies slowly, so that the service stops gracefully.

 

AC

* Timeout is configurable for fetching the endpoint (through environment variables)
* No data is persisted
* Error is logged to the output
* Default response time must be lower than 30 sec, if more than that it is considered slow",,Adam_Aranyi,,,,63cfe31ba05386069cda49af,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i00033:4,DIPP Sprint 3,,,,2.0,,,,,,,Done
Handling the case when BKK Service is down while consuming Alert data,DIPP-38,10037,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Adam_Aranyi,63cfe31ba05386069cda49af,Adam_Aranyi,63cfe31ba05386069cda49af,03/Feb/23 9:51 AM,23/Feb/23 9:23 AM,30/Mar/23 12:59 PM,22/Feb/23 1:52 PM,,0,2_review,,,"As a developer, I want to stop the alert ingestion service when the alert data endpoint is down, so that the service stops gracefully.

 

AC

* Timeout is configurable for fetching the endpoint (through environment variables)
* No data is persisted
* Error is logged to the output",,Adam_Aranyi,,,,63cfe31ba05386069cda49af,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0000f:i,DIPP Sprint 4,,,,2.0,,,,,,,Done
Create data flow diagram and star schema,DIPP-36,10035,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,03/Feb/23 9:04 AM,08/Feb/23 1:07 PM,30/Mar/23 12:59 PM,08/Feb/23 1:07 PM,,0,BKK,,,"As a developer, I want to define what input columns should be used and how to transform them, so that the transformation layer can be implemented.

AC

* It follows the designed [schema|https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management]
* It is documented and available on Confluence",,Adam Brett,,,,63d39e92f6e1b543161772c7,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i00039:9,DIPP Sprint 2,,,,,,,,,10022,Schema management,Done
Timeout is introduced for the Position Ingestion when BKK Service replies slowly,DIPP-35,10034,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Levente_Nagy1,63cfe31bf386bda5dcab317d,Andor Herendi,63ce6514f6e1b5431616179f,Andor Herendi,63ce6514f6e1b5431616179f,01/Feb/23 2:31 PM,20/Feb/23 2:03 PM,30/Mar/23 12:59 PM,20/Feb/23 2:03 PM,,0,,,,"As a developer, I want to stop the position ingestion service when the position data endpoint replies slowly, so that the service stops gracefully.



AC

* Timeout is configurable for fetching the endpoint (through environment variables)
* No data is persisted
* Error is logged to the output
* Default response time must be lower than 30 sec, if more than that it is considered slow",,Andor Herendi,,,,63ce6514f6e1b5431616179f,,,,,,,,,,,,,,,,,DIPP-31,,,,,,,,,,,0|i00033:6,DIPP Sprint 3,,,,2.0,,,,,,,Done
Handling the case when BKK Service is down while consuming Position data,DIPP-34,10033,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Levente_Nagy1,63cfe31bf386bda5dcab317d,Andor Herendi,63ce6514f6e1b5431616179f,Andor Herendi,63ce6514f6e1b5431616179f,01/Feb/23 2:30 PM,20/Feb/23 2:03 PM,30/Mar/23 12:59 PM,20/Feb/23 2:03 PM,,0,,,,"As a developer, I want to stop the position ingestion service when the position data endpoint is down, so that the service stops gracefully.



AC

* Timeout is configurable for fetching the endpoint (through environment variables)
* No data is persisted
* Error is logged to the output",,Andor Herendi,,,,63ce6514f6e1b5431616179f,,,,,,,,,,,,,,,,,DIPP-30,,,,,,,,,,,0|i00033:5,DIPP Sprint 3,,,,2.0,,,,,,,Done
Position Ingestion is contrainerized,DIPP-33,10032,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Andor Herendi,63ce6514f6e1b5431616179f,Andor Herendi,63ce6514f6e1b5431616179f,01/Feb/23 2:29 PM,07/Mar/23 8:53 AM,30/Mar/23 12:59 PM,07/Mar/23 8:53 AM,,0,2_approve,,,,,Andor Herendi,,,,63ce6514f6e1b5431616179f,,,,,,,,,,,,,,,,,,DIPP-32,,,,,,,,,,0|i0000f:d,DIPP Sprint 4,,,,1.0,,,,,10021,Docker Compose,Done
Trip Ingestion is containerized,DIPP-32,10031,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Andor Herendi,63ce6514f6e1b5431616179f,Andor Herendi,63ce6514f6e1b5431616179f,01/Feb/23 2:29 PM,07/Mar/23 8:53 AM,30/Mar/23 12:59 PM,07/Mar/23 8:53 AM,,0,2_approve,,,"As a developer, I want to containerize the trip ingestion, so that can run as a platform-independent service.



AC

* Ingestion can be executed and can be configured through Docker
* The same Java version must be used through the build as the application written",,Andor Herendi,,,,63ce6514f6e1b5431616179f,,,,,,,,,,,,,,,DIPP-40,DIPP-42,,,DIPP-33,,,,,,,,,0|i0000f:9,DIPP Sprint 4,,,,5.0,,,,,10021,Docker Compose,Done
Timeout is introduced for the Trip Ingestion when BKK Service replies slowly,DIPP-31,10030,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Andor Herendi,63ce6514f6e1b5431616179f,Andor Herendi,63ce6514f6e1b5431616179f,01/Feb/23 2:29 PM,20/Feb/23 9:10 AM,30/Mar/23 12:59 PM,20/Feb/23 9:10 AM,,0,3_review,,,"As a developer, I want to stop the trip ingestion service when the trip data endpoint replies slowly, so that the service stops gracefully.



AC

* Timeout is configurable for fetching the endpoint (through environment variables)
* No data is persisted
* Error is logged to the output
* Default response time must be lower than 30 sec, if more than that it is considered slow",,Andor Herendi,,,,63ce6514f6e1b5431616179f,,,,,,,,,,,,,,,DIPP-35,,,,,,,,,,,,,0|i00039:1,DIPP Sprint 3,,,,3.0,,,,,,,Done
Handling the case when BKK Service is down while consuming Trip data,DIPP-30,10029,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Levente_Nagy1,63cfe31bf386bda5dcab317d,Andor Herendi,63ce6514f6e1b5431616179f,Andor Herendi,63ce6514f6e1b5431616179f,01/Feb/23 2:28 PM,20/Feb/23 9:12 AM,30/Mar/23 12:59 PM,20/Feb/23 9:12 AM,,0,,,,"As a developer, I want to stop the trip ingestion service when the trip data endpoint is down, so that the service stops gracefully.



AC

* Timeout is configurable for fetching the endpoint (through environment variables)
* No data is persisted
* Error is logged to the output",,Andor Herendi,Levente_Nagy1,,,63ce6514f6e1b5431616179f,63cfe31bf386bda5dcab317d,,,,,,,,,,,,,,DIPP-34,,,,,,,,,,,,,0|i00033:9,DIPP Sprint 3,,,,3.0,"14/Feb/23 1:45 PM;63cfe31bf386bda5dcab317d;It was done in DIPP-31
Link: [https://dataint23.atlassian.net/browse/DIPP-31|https://dataint23.atlassian.net/browse/DIPP-31|smart-link] ",,,,,,Done
Code coverage are measured in Java module (Vehicle position and trip updates),DIPP-29,10028,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Andor Herendi,63ce6514f6e1b5431616179f,Andor Herendi,63ce6514f6e1b5431616179f,01/Feb/23 2:26 PM,10/Feb/23 10:06 AM,30/Mar/23 12:59 PM,10/Feb/23 10:06 AM,,0,,,,"As a developer, I want to measure the code coverage of individual modules, so that I can be more certain relevant code paths are complying the expected behavior.



Acceptance Criteria (AC)

* Jacoco must be used to measure code coverage
* Report to be created about code coverage (should not be stored anywhere)
* Minimum coverage is not lower than 60%
* If the target is not met then the build should fail",,Andor Herendi,Gábor Fábián,,,63ce6514f6e1b5431616179f,63cfe31ba197e05f9dad5aa6,,,,,,,,,,,,,,DIPP-49,,,,,,,,,,,,,0|i0003a:w,DIPP Sprint 2,,,,5.0,"08/Feb/23 10:31 AM;63cfe31ba197e05f9dad5aa6;On what element are we measuring code coverage?

* *BUNDLE*
* -PACKAGE-
* -CLASS-

What coverage counter should we use?

* *INSTRUCTION*
* -BRANCH-

Do we want a rule for the number of missed classes?

*NO*

Do we want to have cyclomatic complecity check as well?

*NO*",,,,,,Done
Create business glossary,DIPP-27,10026,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,Adam Brett,63d39e92f6e1b543161772c7,31/Jan/23 3:35 PM,07/Feb/23 9:14 AM,30/Mar/23 12:59 PM,07/Feb/23 9:14 AM,,0,,,,"Create a glossary of BKK related terms and their definitions.

Upload it to wiki page.
[https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|https://dataint23.atlassian.net/wiki/spaces/SD/pages/753665/Datawarehouse+schema+management|smart-link] ",,Adam Brett,Andor Herendi,Peter_Hegedus3,Sandor Kazi,63d39e92f6e1b543161772c7,63ce6514f6e1b5431616179f,63cfe31b16dfc2b1fbca1f76,62fbb4260bb03d8a6cb28491,,,,,,,,,,,,,,,,,,,,,,,,,0|i0003b:,DIPP Sprint 1,,,,,06/Feb/23 1:34 PM;63ce6514f6e1b5431616179f;LGTM,"06/Feb/23 1:37 PM;62fbb4260bb03d8a6cb28491;vehicle_sid úgyfelejtődött, amúgy jó lesz.",06/Feb/23 2:31 PM;63cfe31b16dfc2b1fbca1f76;LGTM,,10022,Schema management,Done
Create a mock docker container for a java application,DIPP-26,10025,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Peter_Hegedus3,63cfe31b16dfc2b1fbca1f76,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 3:21 PM,10/Feb/23 9:30 AM,30/Mar/23 12:59 PM,10/Feb/23 9:30 AM,,0,,,,,,Peter_Hegedus3,Tamas Adami,,,63cfe31b16dfc2b1fbca1f76,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,DIPP-22,,,,,,,,,,0|i00039:2,DIPP Sprint 2,,,,,31/Jan/23 11:54 AM;63cfe31b16dfc2b1fbca1f76;GitLab branch feature/DIPP-26 access: [https://githyd.epam.com/peter_hegedus3/bkk-opendata-python/-/tree/feature/DIPP-26|https://githyd.epam.com/peter_hegedus3/bkk-opendata-python/-/tree/feature/DIPP-26],31/Jan/23 11:57 AM;63cfe31b16dfc2b1fbca1f76;PR: [https://githyd.epam.com/peter_hegedus3/bkk-opendata-python/-/merge_requests/1|https://githyd.epam.com/peter_hegedus3/bkk-opendata-python/-/merge_requests/1],,,,,Done
Investigate Futár API,DIPP-25,10024,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Andor Herendi,63ce6514f6e1b5431616179f,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 3:17 PM,08/Feb/23 1:05 PM,30/Mar/23 12:59 PM,08/Feb/23 1:05 PM,,0,,,,,,Adam_Posta,Tamas Adami,,,63cfe31bc565900ff4050272,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,DIPP-15,,,,,,,,,,0|i00039:i,DIPP Sprint 2,,,,,31/Jan/23 5:54 PM;63cfe31bc565900ff4050272;Updated [https://dataint23.atlassian.net/wiki/spaces/SD/pages/33147/Scope|https://dataint23.atlassian.net/wiki/spaces/SD/pages/33147/Scope|smart-link] ,,,,,,Done
Ingestion - Időjárás,DIPP-24,10023,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Levente_Nagy1,63cfe31bf386bda5dcab317d,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 12:49 PM,13/Feb/23 12:34 PM,30/Mar/23 12:59 PM,13/Feb/23 12:34 PM,,0,Ingestion,,,PR: [https://githyd.epam.com/levente_nagy1/dipp_weather_data_ingestion/-/merge_requests/1|https://githyd.epam.com/levente_nagy1/dipp_weather_data_ingestion/-/merge_requests/1],,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,DIPP-15,,,,,,,,,,0|i00039:1i,DIPP Sprint 2,,,,,13/Feb/23 9:10 AM;557058:75793878-96f9-421a-b729-5480491e22d6;3 review done ✅ ,,,,,,Done
Schema management,DIPP-23,10022,Epic,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam Brett,63d39e92f6e1b543161772c7,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 12:47 PM,23/Feb/23 12:17 PM,30/Mar/23 12:59 PM,08/Feb/23 1:07 PM,20/Feb/23 12:00 AM,0,,,,"* create a business glossary
* identify what columns are necessary for product
* create data flow diagram (DFD)
* create star schema",,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0000m:y,,,,,,,,,,,,Done
Docker Compose,DIPP-22,10021,Epic,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Peter_Hegedus3,63cfe31b16dfc2b1fbca1f76,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 12:46 PM,28/Mar/23 5:07 PM,30/Mar/23 12:59 PM,28/Mar/23 5:07 PM,,0,,,,cc [~accountid:62fbb4260bb03d8a6cb28491] ,,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,,DIPP-26,,,,,,,,,0|i0000m:z,,,,29/Jan/23 12:00 AM,,,,,,,,Done
Ingestion - Alerts,DIPP-21,10020,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam_Aranyi,63cfe31ba05386069cda49af,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 12:41 PM,13/Feb/23 2:29 PM,30/Mar/23 12:59 PM,13/Feb/23 2:29 PM,,0,Ingestion,,,,,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,DIPP-15,,,,,,,,,,0|i00039:19,DIPP Sprint 2,,,,,,,,,,,Done
Ingestion Futár,DIPP-20,10019,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 12:40 PM,20/Feb/23 5:16 PM,30/Mar/23 12:59 PM,20/Feb/23 5:16 PM,,0,2_review,Ingestion,,,,Botond_Besnyi,Gábor Fábián,Tamas Adami,,63cfe31bc7e5fd35203b3219,63cfe31ba197e05f9dad5aa6,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,DIPP-15,,,,,,,,,,0|i00033:4i,DIPP Sprint 3,,,,,10/Feb/23 1:17 PM;63cfe31ba197e05f9dad5aa6;[~accountid:63cfe31bc7e5fd35203b3219] egy url-t a PR-hez beraksz kérlek?,10/Feb/23 1:36 PM;63cfe31bc7e5fd35203b3219;[https://git.epam.com/adam_posta/bkk/-/merge_requests/2|https://git.epam.com/adam_posta/bkk/-/merge_requests/2],,,,,Done
Ingestion - Menetrend (Time table),DIPP-19,10018,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 12:21 PM,08/Feb/23 1:59 PM,30/Mar/23 12:59 PM,08/Feb/23 1:59 PM,,0,Ingestion,,,,,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,DIPP-15,,,,,,,,,,,,,,,0|i00039:4,DIPP Sprint 2,,,,,,,,,,,Done
Ingestion - Trip,DIPP-18,10017,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 11:21 AM,09/Feb/23 10:29 AM,30/Mar/23 12:59 PM,08/Feb/23 1:02 PM,,0,,,,,,Gábor Fábián,Tamas Adami,,,63cfe31ba197e05f9dad5aa6,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,DIPP-15,,,,,,,,,,,,,,,,0|i00039:r,DIPP Sprint 2,,,,5.0,27/Jan/23 3:08 PM;63cfe31ba197e05f9dad5aa6;[https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/spark-simple-ingest/src/main/java/com/epam/suhudata01/bkk|https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/spark-simple-ingest/src/main/java/com/epam/suhudata01/bkk],30/Jan/23 5:01 PM;63cfe31ba197e05f9dad5aa6;[https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/retrofit-okhttp-okio|https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/retrofit-okhttp-okio],"02/Feb/23 9:21 AM;63cfe31ba197e05f9dad5aa6;PR: [https://gitbud.epam.com/gabor_fabian1/bkk/-/merge_requests/1|https://gitbud.epam.com/gabor_fabian1/bkk/-/merge_requests/1]

[Internal Data Project|https://dataint23.atlassian.net/jira/people/team/c22d40e4-453d-4ed1-b1e0-51715138cfcb?ref=jira$&src=issue] ([~accountid:63cfe31ba197e05f9dad5aa6] [~accountid:63d39e92f6e1b543161772c7] [~accountid:63cfe31ba05386069cda49af] [~accountid:63cfe31bc565900ff4050272] [~accountid:63cfe31bc7e5fd35203b3219] [~accountid:63cfe31bf386bda5dcab317d] [~accountid:63cfe31bf386bda5dcab317c] [~accountid:63cfe31b16dfc2b1fbca1f76] [~accountid:557058:75793878-96f9-421a-b729-5480491e22d6])",,,,Done
Ingestion - Position,DIPP-17,10016,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 11:21 AM,09/Feb/23 10:29 AM,30/Mar/23 12:59 PM,08/Feb/23 1:02 PM,,0,,,,,,Gábor Fábián,Tamas Adami,,,63cfe31ba197e05f9dad5aa6,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,DIPP-15,,,,,,,,,,,,,,,,0|i0003a:,DIPP Sprint 2,,,,,27/Jan/23 11:53 AM;63cfe31ba197e05f9dad5aa6;Done in Java,27/Jan/23 3:08 PM;63cfe31ba197e05f9dad5aa6;[https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/spark-simple-ingest/src/main/java/com/epam/suhudata01/bkk|https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/spark-simple-ingest/src/main/java/com/epam/suhudata01/bkk],30/Jan/23 5:01 PM;63cfe31ba197e05f9dad5aa6;[https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/retrofit-okhttp-okio|https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/retrofit-okhttp-okio],"02/Feb/23 9:20 AM;63cfe31ba197e05f9dad5aa6;PR: [https://gitbud.epam.com/gabor_fabian1/bkk/-/merge_requests/1|https://gitbud.epam.com/gabor_fabian1/bkk/-/merge_requests/1]

[Internal Data Project|https://dataint23.atlassian.net/jira/people/team/c22d40e4-453d-4ed1-b1e0-51715138cfcb?ref=jira$&src=issue] ([~accountid:63cfe31ba197e05f9dad5aa6] [~accountid:63d39e92f6e1b543161772c7] [~accountid:63cfe31ba05386069cda49af] [~accountid:63cfe31bc565900ff4050272] [~accountid:63cfe31bc7e5fd35203b3219] [~accountid:63cfe31bf386bda5dcab317d] [~accountid:63cfe31bf386bda5dcab317c] [~accountid:63cfe31b16dfc2b1fbca1f76] [~accountid:557058:75793878-96f9-421a-b729-5480491e22d6])",,,Done
Data Transformation,DIPP-16,10015,Epic,To Do,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,,,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 11:06 AM,06/Feb/23 9:20 AM,30/Mar/23 12:59 PM,,,0,,,,,,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i00033:,,,,,,,,,,,,To Do
Data Ingestion,DIPP-15,10014,Feature,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,,,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,27/Jan/23 11:06 AM,23/Feb/23 9:23 AM,30/Mar/23 12:59 PM,23/Feb/23 9:23 AM,,0,,,,,,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,DIPP-19,DIPP-17,DIPP-18,,,,,DIPP-20,DIPP-21,DIPP-24,DIPP-25,,,,,,0|i0000j:,,,,,,,,,,10001,Create report from BKK data,Done
Load TripUpdates data and save it as Avro,DIPP-14,10013,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Gábor Fábián,63cfe31ba197e05f9dad5aa6,27/Jan/23 10:19 AM,24/Feb/23 9:13 AM,30/Mar/23 12:59 PM,24/Feb/23 9:13 AM,,0,,,,,,Gábor Fábián,,,,63cfe31ba197e05f9dad5aa6,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0002n:,,,,,,27/Jan/23 3:06 PM;63cfe31ba197e05f9dad5aa6;[https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/spark-simple-ingest/src/main/java/com/epam/suhudata01/bkk|https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/spark-simple-ingest/src/main/java/com/epam/suhudata01/bkk],,,,,,Done
Realtime bus locations visualization on map,DIPP-13,10012,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Gábor Fábián,63cfe31ba197e05f9dad5aa6,26/Jan/23 10:07 AM,27/Jan/23 10:17 AM,30/Mar/23 12:59 PM,27/Jan/23 10:16 AM,,0,,,,,,Gábor Fábián,,,,63cfe31ba197e05f9dad5aa6,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0002f:,,,,,,,,,,,,Done
Make correlations between bus delays and rainfall,DIPP-12,10011,Story,To Do,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,Adam_Aranyi,63cfe31ba05386069cda49af,Adam_Aranyi,63cfe31ba05386069cda49af,Adam_Aranyi,63cfe31ba05386069cda49af,26/Jan/23 9:33 AM,26/Jan/23 9:33 AM,30/Mar/23 12:59 PM,,,0,,,,,,Adam_Aranyi,,,,63cfe31ba05386069cda49af,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i00027:,,,,,,,,,,,,To Do
Categorize and normalize fields in gtfs data,DIPP-11,10010,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Peter_Hegedus3,63cfe31b16dfc2b1fbca1f76,Peter_Hegedus3,63cfe31b16dfc2b1fbca1f76,Peter_Hegedus3,63cfe31b16dfc2b1fbca1f76,26/Jan/23 9:30 AM,24/Feb/23 9:19 AM,30/Mar/23 12:59 PM,24/Feb/23 9:19 AM,,0,,,,"There are optional and required fields in GTFS data, some field names are missing from realtime data, others are not filled with data (like congestion_level).",,Peter_Hegedus3,,,,63cfe31b16dfc2b1fbca1f76,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0001z:,,,,,,,,,,,,Done
Create a Visualization,DIPP-10,10009,Epic,In Progress,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,,,David_Brozovics,63cfe31b5a23f7e717cdbbc5,David_Brozovics,63cfe31b5a23f7e717cdbbc5,26/Jan/23 9:23 AM,28/Feb/23 2:42 PM,30/Mar/23 12:59 PM,,19/Apr/23 12:00 AM,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0003n:,,,,07/Mar/23 12:00 AM,,,,,,,,In Progress
"Implement end to end data processing: ingest, transform, visualize",DIPP-9,10008,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Adam_Posta,63cfe31bc565900ff4050272,Adam_Posta,63cfe31bc565900ff4050272,Adam_Posta,63cfe31bc565900ff4050272,26/Jan/23 8:49 AM,24/Feb/23 9:17 AM,30/Mar/23 12:59 PM,24/Feb/23 9:17 AM,,0,,,,,,Adam_Posta,,,,63cfe31bc565900ff4050272,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0001j:,,,,,,,,,,,,Done
Load data into pandas dataframe and visualize it,DIPP-8,10007,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Levente_Nagy1,63cfe31bf386bda5dcab317d,Levente_Nagy1,63cfe31bf386bda5dcab317d,Levente_Nagy1,63cfe31bf386bda5dcab317d,25/Jan/23 5:42 PM,24/Feb/23 9:17 AM,30/Mar/23 12:59 PM,24/Feb/23 9:17 AM,,0,,,,,,Levente_Nagy1,,,,63cfe31bf386bda5dcab317d,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0001b:,,,,,,,,,,,,Done
Translate GTFS fields into spark dataframe,DIPP-7,10006,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Peter_Hegedus3,63cfe31b16dfc2b1fbca1f76,Peter_Hegedus3,63cfe31b16dfc2b1fbca1f76,Peter_Hegedus3,63cfe31b16dfc2b1fbca1f76,25/Jan/23 5:01 PM,24/Feb/23 9:17 AM,30/Mar/23 12:59 PM,24/Feb/23 9:17 AM,,0,,,,,,Peter_Hegedus3,,,,63cfe31b16dfc2b1fbca1f76,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i00013:,,,,,,,,,,,,Done
Read data into spark dataframes,DIPP-6,10005,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Botond_Besnyi,63cfe31bc7e5fd35203b3219,Botond_Besnyi,63cfe31bc7e5fd35203b3219,25/Jan/23 1:26 PM,24/Feb/23 9:17 AM,30/Mar/23 12:59 PM,24/Feb/23 9:17 AM,,0,,,,,,Botond_Besnyi,,,,63cfe31bc7e5fd35203b3219,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0000v:,,,,,,,,,,,,Done
Load realtime GTFS data into Spark (Java),DIPP-5,10004,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Gábor Fábián,63cfe31ba197e05f9dad5aa6,25/Jan/23 9:51 AM,24/Feb/23 9:13 AM,30/Mar/23 12:59 PM,24/Feb/23 9:13 AM,,0,,,,,,Gábor Fábián,,,,63cfe31ba197e05f9dad5aa6,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0000n:,,,,,,27/Jan/23 3:07 PM;63cfe31ba197e05f9dad5aa6;[https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/spark-simple-ingest/src/main/java/com/epam/suhudata01/bkk|https://gitbud.epam.com/gabor_fabian1/bkk/-/tree/spark-simple-ingest/src/main/java/com/epam/suhudata01/bkk],,,,,,Done
Check BKK's data,DIPP-3,10002,Story,Done,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,Done,Gábor Fábián,63cfe31ba197e05f9dad5aa6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,24/Jan/23 3:12 PM,27/Jan/23 10:17 AM,30/Mar/23 12:59 PM,27/Jan/23 10:17 AM,,0,,,,,,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i0000f:,,,,,,,,,,10001,Create report from BKK data,Done
Create report from BKK data,DIPP-2,10001,Epic,In Progress,DIPP,Data Internal Public Project,software,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,,Medium,,,,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,Tamas Adami,557058:75793878-96f9-421a-b729-5480491e22d6,24/Jan/23 3:09 PM,28/Feb/23 2:10 PM,30/Mar/23 12:59 PM,,30/Apr/23 12:00 AM,0,BKK,,,"Create report from BKK data

+*Data*+

*Public transport*

* BKK's data (even real-time) is available (for fair use) from open data: [https://opendata.bkk.hu/data-sources|https://opendata.bkk.hu/data-sources|smart-link] 
* Transit feed historicals are available here: [https://transitfeeds.com/p/bkk/42|https://transitfeeds.com/p/bkk/42|smart-link] 

*Weather data*

* Hungarian weather data: [https://odp.met.hu/|https://odp.met.hu/|smart-link] 

 

h2. +Product+

The baseline data product would be something similar to [https://mav-stat.info/|https://mav-stat.info/|smart-link] 

The first two features are the followings:

+*# 1 Delays*+ 

# Delay per BKK public transport traffic lines should be shown for the vehicles listed below. Delay for the whole line not between stops. This is historical data.
# Delay per vehicle. The actual delay should be shown in real-time on a map.



# bus
# trolley
# tram
# metro
# suburban railway
# boat



+*# 2 Alerts*+ - Any alerts (service changes)?

The first step should have same basic functionalities as the [https://bkk.hu/en/bkk-info/|https://bkk.hu/en/bkk-info/|smart-link]



Further along the line:

* Weather data integration
* Data transformations for the base model to predict times      ",,Tamas Adami,,,,557058:75793878-96f9-421a-b729-5480491e22d6,,,,,,,,,,,,,,,,,,,,,,,,,,,,0|i00007:,,,,31/Jan/23 12:00 AM,,,,,,,,In Progress
